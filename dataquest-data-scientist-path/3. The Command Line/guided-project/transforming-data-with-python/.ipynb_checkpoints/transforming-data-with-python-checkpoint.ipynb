{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Project: Transforming data with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this project, you'll be working with a dataset of submissions to [Hacker News](http://news.ycombinator.com/) from 2006 to 2015. \n",
    "Hacker News is a site where users can submit articles from across the internet (usually about technology and startups), and others can \"upvote\" the articles, signifying that they like them. The more upvotes a submission gets, the more popular it was in the community. Popular articles get to the \"front page\" of Hacker News, where they're more likely to be seen by others.<br>\n",
    "\n",
    "The dataset you'll be using was compiled by Arnaud Drizard using the Hacker News API, and can be found [here](https://github.com/arnauddri/hn). We've sampled 10000 rows from the data randomly, and removed all extraneous columns. **Our dataset only has four columns**:\n",
    "\n",
    "* submission_time -- when the story was submitted.\n",
    "* upvotes -- number of upvotes the submission got.\n",
    "* url -- the base domain of the submission.\n",
    "* headline -- the headline of the submission. Users can edit this, and it doesn't have to match the headline of the original article.\n",
    "\n",
    "### You'll be writing scripts to answer some main questions:\n",
    "\n",
    "What words appear most often in the headlines?\n",
    "What domains were submitted most often to Hacker News?\n",
    "At what times are the most articles submitted?\n",
    "You'll be answering these questions by writing command line scripts, instead of using IPython notebook. IPython notebooks are great for quick data visualization and exploration, but Python scripts are the way to put anything we learn into production. Let's say you want to make a website to help people write headlines that get as many upvotes as possible, and submit articles at the right time. To do this, you'll need scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the read.py file, read the hn_stories.csv file into a Pandas Dataframe.\n",
    "* There is no header row in the data, so the columns don't have names. See this [stackoverflow thread for how to add column names](http://stackoverflow.com/questions/11346283/renaming-columns-in-pandas). Add the column names from the last screen (submission_time, upvotes, url, and headline) to the Dataframe.\n",
    "* Create a function called load_data that takes no inputs, but contains the code to read in and process the dataset. load_data should return a Pandas Dataframe with the column names set correctly.\n",
    "\n",
    "As you work on these steps, you should be running your script on the command line every so often and verifying that things are working. You can run read.py from the command line by calling python read.py. \n",
    "* The first verification is to make sure that you don't see any errors. \n",
    "* The second one is to call print at key points in your code, and make sure that the output looks like what you expect. \n",
    "* You might want to do this after each step above. This is a good general rule of thumb to follow when writing new code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "\n",
    "/home/dq/scripts$ ls -la\n",
    "total 840                                   \n",
    "drwxr-xr-x 2 dq dq   4096 Nov 13 07:36 .    \n",
    "drwxr-xr-x 1 dq dq   4096 Nov 13 09:04 ..   \n",
    "-rwxr-xr-x 1 dq dq 851754 Nov 13 07:36 hn_stories.csv\n",
    "-rwxrwxrwx 1 dq dq      0 Nov 13 09:11 read.py\n",
    "/home/dq/scripts$ nano read.py\n",
    "\n",
    "---\n",
    "import pandas as pd\n",
    "\n",
    "def load_data():\n",
    "    stories = pd.read_csv('hn_stories.csv')\n",
    "    stories.columns = ['submission_time', 'upvotes', 'url', 'headline']\n",
    "    return stories\n",
    "---\n",
    "\n",
    "/home/dq/scripts$ \n",
    "/home/dq/scripts$ \n",
    "/home/dq/scripts$ \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to figure out which words appear most often in the headlines. We'll be developing another script, called `count.py` to accomplish this. We'll need to import our load_data function from `read.py` into `count.py` so we can use it.\n",
    "\n",
    "You'll recall that if you have a folder with two files, `read.py` and `count.py`, you can use the function `load_data` in `read.py` from `count.py` by writing the following code in count.py:\n",
    "\n",
    "```bash\n",
    "import read\n",
    "df = read.load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "\n",
    "---count.py\n",
    "\n",
    "import read\n",
    "from collections import Counter\n",
    "\n",
    "data = read.load_data()\n",
    "data_ = data[data['headline'].notnull()]\n",
    "\n",
    "headlines = ' '.join(data_['headline'])\n",
    "headlines = headlines.lower()\\\n",
    ".replace('(','')\\\n",
    ".replace(')','')\\\n",
    ".replace('?','')\n",
    "\n",
    "head_split = headlines.split(' ')\n",
    "\n",
    "c = Counter(head_split)\n",
    "print(c.most_common(100))\n",
    "\n",
    "---\n",
    "\n",
    "[('the', 2051), ('to', 1643), ('a', 1279), ('of', 1174), ('for', 1143)\n",
    ", ('in', 1042), ('and', 960), ('', 740), ('is', 621), ('on', 573), ('w\n",
    "ith', 541), ('hn:', 537), ('how', 529), ('-', 487), ('your', 480), ('y\n",
    "ou', 401), ('ask', 371), ('from', 314), ('google', 308), ('new', 305),\n",
    " ('why', 266), ('what', 262), ('an', 245), ('are', 223), ('by', 222), ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
